{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing clustering stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dependencies and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import dirname, abspath, join, exists\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "from rpy2.rinterface_lib.embedded import RRuntimeError\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "clue = importr(\"clue\")\n",
    "bootcluster = importr(\"bootcluster\")\n",
    "OTclust = importr(\"OTclust\")\n",
    "\n",
    "from config.definitions import ROOT_DIR\n",
    "os.chdir(ROOT_DIR + '\\\\src\\\\model\\\\')\n",
    "\n",
    "from src.stability_algorithms.compute_stability_exp_args import ComputerStabilityArguments\n",
    "\n",
    "import traceback\n",
    "from transformers import HfArgumentParser\n",
    "\n",
    "rng = np.random.RandomState(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering stability methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stability:\n",
    "\n",
    "    \"\"\"\n",
    "    Class to compute stability using CPU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stability_args, ROOT_DIR):\n",
    "        self.stability_args = stability_args\n",
    "        self.ROOT_DIR = ROOT_DIR\n",
    "\n",
    "    def run(self, \n",
    "            data, \n",
    "    ):\n",
    "        \"\"\"\n",
    "            param: data\n",
    "            size_sample: size_sample\n",
    "        \"\"\"\n",
    "        data = data \n",
    "        size_sample = data.shape[0]\n",
    "        clusters = self.stability_args.clusters\n",
    "        num_bootstrap_samples = self.stability_args.num_bootstrap_samples\n",
    "        num_train_epochs = self.stability_args.num_train_epochs\n",
    "        path_and_file_name_to_save = self.stability_args.output_dir +  self.stability_args.output_stab_name\n",
    "        project_name = self.stability_args.project_name\n",
    "        random_state = self.stability_args.RNDN\n",
    "        \n",
    "        manager = Manager()\n",
    "        stab_methods = manager.dict()\n",
    "        stab_methods[\"adjusted_rand_score\"] = manager.list()\n",
    "        stab_methods[\"adjusted_mutual_info_score\"] = manager.list()\n",
    "        stab_methods[\"bagclust\"] = manager.list()\n",
    "        stab_methods[\"han\"] = manager.list()\n",
    "        stab_methods[\"OTclust\"] = manager.list()\n",
    "\n",
    "        arguments = {\n",
    "            \"clusters\": clusters, \n",
    "            \"num_train_epochs\": num_train_epochs,\n",
    "            \"num_bootstrap_samples\": num_bootstrap_samples,\n",
    "            \"random_state\": random_state\n",
    "        }\n",
    "        stab_epochs = {}\n",
    "\n",
    "        rData = None\n",
    "        with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            rData = ro.conversion.rpy2py(data)\n",
    "    \n",
    "        for ep in tqdm(range(num_train_epochs)):\n",
    "            for cluster in clusters:\n",
    "\n",
    "                kmeans = KMeans(n_clusters=cluster, n_init=10)\n",
    "                labels, indices = self.get_labels_and_indices(data, kmeans, size_sample, num_bootstrap_samples, random_state)    \n",
    "\n",
    "                if self.stability_args.adjusted_rand_score: self.adjusted_rand_score(labels, indices, cluster, stab_methods)\n",
    "                if self.stability_args.adjusted_mutual_info_score: self.adjusted_mutual_info_score(labels, indices, cluster, stab_methods)\n",
    "                if self.stability_args.bagclust: self.bagclust(rData, num_bootstrap_samples, cluster, stab_methods)\n",
    "                if self.stability_args.han: self.han(rData, num_bootstrap_samples, cluster, stab_methods)\n",
    "                if self.stability_args.OTstab: self.OTstab(rData, num_bootstrap_samples, cluster, stab_methods)\n",
    "\n",
    "            \n",
    "            #To JSON serialize \n",
    "            stab_methods = dict(stab_methods)\n",
    "            for k in stab_methods.keys():\n",
    "                stab_methods[k] = list(stab_methods[k])\n",
    "        \n",
    "            stab_epochs[ep] = stab_methods            \n",
    "            stab_methods = manager.dict()\n",
    "            stab_methods[\"adjusted_rand_score\"] = manager.list()\n",
    "            stab_methods[\"adjusted_mutual_info_score\"] = manager.list()\n",
    "            stab_methods[\"bagclust\"] = manager.list()\n",
    "            stab_methods[\"han\"] = manager.list()\n",
    "            stab_methods[\"OTclust\"] = manager.list()\n",
    "        print(stab_epochs)   \n",
    "        self.save(stab_epochs, arguments, path_and_file_name_to_save)\n",
    "\n",
    "    def get_labels_and_indices(self, data, clrt_algorithm, size_sample, num_bootstrap_samples, random_state):\n",
    "        labels = []\n",
    "        indices = []\n",
    "        for _ in range(num_bootstrap_samples):\n",
    "            # draw bootstrap samples, store indices\n",
    "            sample_indices = rng.randint(0, data.shape[0], size_sample)\n",
    "            indices.append(sample_indices)\n",
    "            clrt_algorithm = clone(clrt_algorithm)\n",
    "            if hasattr(clrt_algorithm, \"random_state\"):\n",
    "                # randomize estimator if possible\n",
    "                clrt_algorithm.random_state = rng.randint(1e5)\n",
    "            data_bootstrap = data[sample_indices]\n",
    "            clrt_algorithm.fit(data_bootstrap)\n",
    "            # store clustering outcome using original indices\n",
    "            relabel = -np.ones(data.shape[0], dtype=int)\n",
    "            relabel[sample_indices] = clrt_algorithm.labels_\n",
    "            labels.append(relabel)\n",
    "        return (labels, indices)\n",
    "\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html\n",
    "    def adjusted_rand_score(self, labels, indices, cluster, stab_methods):\n",
    "        scores = []\n",
    "        for l, i in zip(labels, indices):\n",
    "            for k, j in zip(labels, indices):\n",
    "                in_both = np.intersect1d(i, j)\n",
    "                scores.append(adjusted_rand_score(l[in_both], k[in_both])) \n",
    "        stab_methods['adjusted_rand_score'].append(np.mean(scores))\n",
    "\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html\n",
    "    def adjusted_mutual_info_score(self, labels, indices, cluster, stab_methods):\n",
    "        scores = []\n",
    "        for l, i in zip(labels, indices):\n",
    "            for k, j in zip(labels, indices):\n",
    "                in_both = np.intersect1d(i, j)\n",
    "                scores.append(adjusted_mutual_info_score(l[in_both], k[in_both]))\n",
    "        stab_methods['adjusted_mutual_info_score'].append(np.mean(scores))\n",
    "\n",
    "    #\"A prediction-based resampling method for estimating the number of clusters in a dataset.\"\n",
    "    #\"Bagging to improve the accuracy of a clustering procedure.\"\n",
    "    #Explicação: Stability estimation for unsupervised clustering: A review\n",
    "    def bagclust(self, rData, num_bootstrap_samples, n_cluster, stab_methods):\n",
    "        rDataStab = clue.cl_bag(x = rData, B = num_bootstrap_samples, k = n_cluster)\n",
    "        stab_methods['bagclust'].append(rDataStab.rx2['.Data'].max(axis = 1).mean())\n",
    "\n",
    "    #Bootstrapping estimates of stability for clusters,observations and model selection\n",
    "    #Para entender vá para a página 4 Seção 2 Fig. 1.\n",
    "    def han(self, rData, num_bootstrap_samples, n_cluster, stab_methods):\n",
    "        try:\n",
    "            hanStab = bootcluster.stability(x = rData, k = n_cluster, B = num_bootstrap_samples)\n",
    "            stab_overall = float(0) if math.isnan(float(hanStab.rx2['overall'])) else float(hanStab.rx2['overall'])\n",
    "            stab_methods['han'].append(stab_overall)\n",
    "        except RRuntimeError:\n",
    "            stab_methods['han'].append(float(0))\n",
    "\n",
    "    #CPS Analysis for cluster validation\n",
    "    #Install from github https://github.com/cran/OTclust\n",
    "    #Melhor explicação: Denoising Methods for Inferring Microbiome Community Content and Abundance\n",
    "    def OTstab(self, rData, num_bootstrap_samples, n_cluster,stab_methods): \n",
    "        otclust = OTclust.clustCPS(rData, k=n_cluster, l= False, pre=False, noi=\"after\",\n",
    "                 nPCA = 2, nEXP = num_bootstrap_samples)\n",
    "        stab_methods['OTclust'].append(float(otclust.rx2['tight_all']))\n",
    "\n",
    "    def save(self, stab_epochs, arguments, path_and_file_name_to_save):\n",
    "        data = json.dumps([stab_epochs, arguments], indent = 4)\n",
    "        i = 1\n",
    "        path_and_file_name_to_save = path_and_file_name_to_save.replace(\".json\", \"\")\n",
    "        while os.path.exists(f\"{path_and_file_name_to_save}-{i}.json\"):\n",
    "            i += 1\n",
    "        file = open(f\"{path_and_file_name_to_save}-{i}.json\",\"w\")\n",
    "        file.write(data)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_args = ComputerStabilityArguments(\n",
    "    project_name='Stability - SERIEMA',\n",
    "    data_path=ROOT_DIR + '\\\\src\\\\model\\\\notebook\\\\predict_val.csv',\n",
    "    output_dir=ROOT_DIR + '\\\\src\\\\model\\\\notebook\\\\stability\\\\',\n",
    "    output_stab_name='seriema_stability.json', \n",
    "    clusters=[2], \n",
    "    num_train_epochs=1, \n",
    "    num_bootstrap_samples=50,\n",
    "    num_random_samples=100, \n",
    "    repeat_experimet=1, \n",
    "    output_log_name='seriema_stability.json', \n",
    "    mode='CPU', \n",
    "    adjusted_rand_score=True, \n",
    "    adjusted_mutual_info_score=True, \n",
    "    bagclust=True, \n",
    "    han=True, \n",
    "    OTstab=True, \n",
    "    RNDN=1, \n",
    "    report_to=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\FS-Ma\\AppData\\Local\\Temp\\ipykernel_20944\\3565405784.py:124: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  stab_overall = float(0) if math.isnan(float(hanStab.rx2['overall'])) else float(hanStab.rx2['overall'])\n",
      "R[write to console]: sigma summary: Min. : 1.29679277837393 |1st Qu. : 1.30651787195453 |Median : 1.31796026836825 |Mean : 1.32468814870313 |3rd Qu. : 1.34966030310521 |Max. : 1.40142806249538 |\n",
      "\n",
      "R[write to console]: Epoch: Iteration #100 error is: 17.2985507797968\n",
      "\n",
      "R[write to console]: Epoch: Iteration #200 error is: 1.48454004586345\n",
      "\n",
      "R[write to console]: Epoch: Iteration #300 error is: 1.05184828683321\n",
      "\n",
      "R[write to console]: Epoch: Iteration #400 error is: 0.836561056063635\n",
      "\n",
      "R[write to console]: Epoch: Iteration #500 error is: 0.630685782683862\n",
      "\n",
      "R[write to console]: Epoch: Iteration #600 error is: 0.481402188750329\n",
      "\n",
      "R[write to console]: Epoch: Iteration #700 error is: 0.31131044851946\n",
      "\n",
      "R[write to console]: Epoch: Iteration #800 error is: 0.255595405047772\n",
      "\n",
      "R[write to console]: Epoch: Iteration #900 error is: 0.25080280363011\n",
      "\n",
      "R[write to console]: Epoch: Iteration #1000 error is: 0.247937879574031\n",
      "\n",
      "C:\\Users\\FS-Ma\\AppData\\Local\\Temp\\ipykernel_20944\\3565405784.py:135: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  stab_methods['OTclust'].append(float(otclust.rx2['tight_all']))\n",
      "100%|██████████| 1/1 [00:17<00:00, 17.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'adjusted_rand_score': [0.4449913601727691], 'adjusted_mutual_info_score': [0.47615443665039703], 'bagclust': [0.8047999999999998], 'han': [0.8046883647336893], 'OTclust': [0.3204138469696045]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not exists(stability_args.output_dir):\n",
    "    makedirs(stability_args.output_dir)\n",
    "\n",
    "st = time.time()\n",
    "for i in range(1, stability_args.repeat_experimet + 1):\n",
    "    data = pd.read_csv(stability_args.data_path, skiprows = 0)\n",
    "    if stability_args.num_random_samples:\n",
    "        data = data.sample(n=stability_args.num_random_samples, replace = True)\n",
    "    data = data.to_numpy()\n",
    "\n",
    "    stabO = Stability(stability_args, ROOT_DIR) #TODO: Pass ROOT_DIR from stability_args\n",
    "    stabO.run(data)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time = et - st"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer-segmentation-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
